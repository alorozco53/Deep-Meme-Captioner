{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional net finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard\n",
    "from finetune import load_data, to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dense in module keras.layers.core:\n",
      "\n",
      "class Dense(keras.engine.topology.Layer)\n",
      " |  Just your regular densely-connected NN layer.\n",
      " |  \n",
      " |  `Dense` implements the operation:\n",
      " |  `output = activation(dot(input, kernel) + bias)`\n",
      " |  where `activation` is the element-wise activation function\n",
      " |  passed as the `activation` argument, `kernel` is a weights matrix\n",
      " |  created by the layer, and `bias` is a bias vector created by the layer\n",
      " |  (only applicable if `use_bias` is `True`).\n",
      " |  \n",
      " |  Note: if the input to the layer has a rank greater than 2, then\n",
      " |  it is flattened prior to the initial dot product with `kernel`.\n",
      " |  \n",
      " |  # Example\n",
      " |  \n",
      " |  ```python\n",
      " |      # as first layer in a sequential model:\n",
      " |      model = Sequential()\n",
      " |      model.add(Dense(32, input_shape=(16,)))\n",
      " |      # now the model will take as input arrays of shape (*, 16)\n",
      " |      # and output arrays of shape (*, 32)\n",
      " |  \n",
      " |      # after the first layer, you don't need to specify\n",
      " |      # the size of the input anymore:\n",
      " |      model.add(Dense(32))\n",
      " |  ```\n",
      " |  \n",
      " |  # Arguments\n",
      " |      units: Positive integer, dimensionality of the output space.\n",
      " |      activation: Activation function to use\n",
      " |          (see [activations](../activations.md)).\n",
      " |          If you don't specify anything, no activation is applied\n",
      " |          (ie. \"linear\" activation: `a(x) = x`).\n",
      " |      use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |      kernel_initializer: Initializer for the `kernel` weights matrix\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      bias_initializer: Initializer for the bias vector\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      kernel_regularizer: Regularizer function applied to\n",
      " |          the `kernel` weights matrix\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      bias_regularizer: Regularizer function applied to the bias vector\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      activity_regularizer: Regularizer function applied to\n",
      " |          the output of the layer (its \"activation\").\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      kernel_constraint: Constraint function applied to\n",
      " |          the `kernel` weights matrix\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |      bias_constraint: Constraint function applied to the bias vector\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |  \n",
      " |  # Input shape\n",
      " |      nD tensor with shape: `(batch_size, ..., input_dim)`.\n",
      " |      The most common situation would be\n",
      " |      a 2D input with shape `(batch_size, input_dim)`.\n",
      " |  \n",
      " |  # Output shape\n",
      " |      nD tensor with shape: `(batch_size, ..., units)`.\n",
      " |      For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
      " |      the output would have shape `(batch_size, units)`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dense\n",
      " |      keras.engine.topology.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Container` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Container), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  constraints\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, None, None, 32 864         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, None, None, 32 96          conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, None, None, 32 0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, None, None, 32 9216        activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, None, None, 32 96          conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, None, None, 32 0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, None, None, 64 18432       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, None, None, 64 192         conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, None, None, 64 0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, None, None, 64 0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, None, None, 80 5120        max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, None, None, 80 240         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, None, None, 80 0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, None, None, 19 138240      activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, None, None, 19 576         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, None, None, 19 0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, None, None, 19 0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, None, None, 64 12288       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, None, None, 64 192         conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, None, None, 64 0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, None, None, 48 9216        max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, None, None, 96 55296       activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, None, None, 48 144         conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, None, None, 96 288         conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, None, None, 48 0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, None, None, 96 0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePool (None, None, None, 19 0           max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, None, None, 64 12288       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, None, None, 64 76800       activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, None, None, 96 82944       activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, None, None, 32 6144        average_pooling2d_1[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, None, None, 64 192         conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, None, None, 64 192         conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, None, None, 96 288         conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, None, None, 32 96          conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, None, None, 64 0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, None, None, 64 0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, None, None, 96 0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, None, None, 32 0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)             (None, None, None, 25 0           activation_6[0][0]               \n",
      "                                                                   activation_8[0][0]               \n",
      "                                                                   activation_11[0][0]              \n",
      "                                                                   activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, None, None, 64 16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, None, None, 64 192         conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, None, None, 64 0           batch_normalization_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, None, None, 48 12288       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, None, None, 96 55296       activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, None, None, 48 144         conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, None, None, 96 288         conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, None, None, 48 0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, None, None, 96 0           batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePool (None, None, None, 25 0           mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, None, None, 64 16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, None, None, 64 76800       activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, None, None, 96 82944       activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, None, None, 64 16384       average_pooling2d_2[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, None, None, 64 192         conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, None, None, 64 192         conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, None, None, 96 288         conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, None, None, 64 192         conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, None, None, 64 0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, None, None, 64 0           batch_normalization_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, None, None, 96 0           batch_normalization_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, None, None, 64 0           batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)             (None, None, None, 28 0           activation_13[0][0]              \n",
      "                                                                   activation_15[0][0]              \n",
      "                                                                   activation_18[0][0]              \n",
      "                                                                   activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, None, None, 64 18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, None, None, 64 192         conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, None, None, 64 0           batch_normalization_23[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, None, None, 48 13824       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, None, None, 96 55296       activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, None, None, 48 144         conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, None, None, 96 288         conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, None, None, 48 0           batch_normalization_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, None, None, 96 0           batch_normalization_24[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePool (None, None, None, 28 0           mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, None, None, 64 18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, None, None, 64 76800       activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, None, None, 96 82944       activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, None, None, 64 18432       average_pooling2d_3[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, None, None, 64 192         conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, None, None, 64 192         conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, None, None, 96 288         conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, None, None, 64 192         conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, None, None, 64 0           batch_normalization_20[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, None, None, 64 0           batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, None, None, 96 0           batch_normalization_25[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, None, None, 64 0           batch_normalization_26[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)             (None, None, None, 28 0           activation_20[0][0]              \n",
      "                                                                   activation_22[0][0]              \n",
      "                                                                   activation_25[0][0]              \n",
      "                                                                   activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, None, None, 64 18432       mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, None, None, 64 192         conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, None, None, 64 0           batch_normalization_28[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, None, None, 96 55296       activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNor (None, None, None, 96 288         conv2d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, None, None, 96 0           batch_normalization_29[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, None, None, 38 995328      mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, None, None, 96 82944       activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNor (None, None, None, 38 1152        conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, None, None, 96 288         conv2d_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, None, None, 38 0           batch_normalization_27[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, None, None, 96 0           batch_normalization_30[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, None, None, 28 0           mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)             (None, None, None, 76 0           activation_27[0][0]              \n",
      "                                                                   activation_30[0][0]              \n",
      "                                                                   max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, None, None, 12 98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNor (None, None, None, 12 384         conv2d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, None, None, 12 0           batch_normalization_35[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, None, None, 12 114688      activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNor (None, None, None, 12 384         conv2d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, None, None, 12 0           batch_normalization_36[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)               (None, None, None, 12 98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, None, None, 12 114688      activation_36[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNor (None, None, None, 12 384         conv2d_32[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNor (None, None, None, 12 384         conv2d_37[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, None, None, 12 0           batch_normalization_32[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, None, None, 12 0           batch_normalization_37[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)               (None, None, None, 12 114688      activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, None, None, 12 114688      activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNor (None, None, None, 12 384         conv2d_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNor (None, None, None, 12 384         conv2d_38[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, None, None, 12 0           batch_normalization_33[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, None, None, 12 0           batch_normalization_38[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePool (None, None, None, 76 0           mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)               (None, None, None, 19 147456      mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, None, None, 19 172032      activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)               (None, None, None, 19 172032      activation_38[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)               (None, None, None, 19 147456      average_pooling2d_4[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNor (None, None, None, 19 576         conv2d_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNor (None, None, None, 19 576         conv2d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNor (None, None, None, 19 576         conv2d_39[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNor (None, None, None, 19 576         conv2d_40[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, None, None, 19 0           batch_normalization_31[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, None, None, 19 0           batch_normalization_34[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_39 (Activation)       (None, None, None, 19 0           batch_normalization_39[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_40 (Activation)       (None, None, None, 19 0           batch_normalization_40[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)             (None, None, None, 76 0           activation_31[0][0]              \n",
      "                                                                   activation_34[0][0]              \n",
      "                                                                   activation_39[0][0]              \n",
      "                                                                   activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)               (None, None, None, 16 122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNor (None, None, None, 16 480         conv2d_45[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_45 (Activation)       (None, None, None, 16 0           batch_normalization_45[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)               (None, None, None, 16 179200      activation_45[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNor (None, None, None, 16 480         conv2d_46[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_46 (Activation)       (None, None, None, 16 0           batch_normalization_46[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)               (None, None, None, 16 122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)               (None, None, None, 16 179200      activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNor (None, None, None, 16 480         conv2d_42[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNor (None, None, None, 16 480         conv2d_47[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_42 (Activation)       (None, None, None, 16 0           batch_normalization_42[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_47 (Activation)       (None, None, None, 16 0           batch_normalization_47[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)               (None, None, None, 16 179200      activation_42[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)               (None, None, None, 16 179200      activation_47[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNor (None, None, None, 16 480         conv2d_43[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNor (None, None, None, 16 480         conv2d_48[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_43 (Activation)       (None, None, None, 16 0           batch_normalization_43[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_48 (Activation)       (None, None, None, 16 0           batch_normalization_48[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePool (None, None, None, 76 0           mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)               (None, None, None, 19 147456      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)               (None, None, None, 19 215040      activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)               (None, None, None, 19 215040      activation_48[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)               (None, None, None, 19 147456      average_pooling2d_5[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNor (None, None, None, 19 576         conv2d_41[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNor (None, None, None, 19 576         conv2d_44[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNor (None, None, None, 19 576         conv2d_49[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNor (None, None, None, 19 576         conv2d_50[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_41 (Activation)       (None, None, None, 19 0           batch_normalization_41[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_44 (Activation)       (None, None, None, 19 0           batch_normalization_44[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_49 (Activation)       (None, None, None, 19 0           batch_normalization_49[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_50 (Activation)       (None, None, None, 19 0           batch_normalization_50[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)             (None, None, None, 76 0           activation_41[0][0]              \n",
      "                                                                   activation_44[0][0]              \n",
      "                                                                   activation_49[0][0]              \n",
      "                                                                   activation_50[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)               (None, None, None, 16 122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNor (None, None, None, 16 480         conv2d_55[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_55 (Activation)       (None, None, None, 16 0           batch_normalization_55[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)               (None, None, None, 16 179200      activation_55[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNor (None, None, None, 16 480         conv2d_56[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_56 (Activation)       (None, None, None, 16 0           batch_normalization_56[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)               (None, None, None, 16 122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)               (None, None, None, 16 179200      activation_56[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNor (None, None, None, 16 480         conv2d_52[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNor (None, None, None, 16 480         conv2d_57[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_52 (Activation)       (None, None, None, 16 0           batch_normalization_52[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_57 (Activation)       (None, None, None, 16 0           batch_normalization_57[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)               (None, None, None, 16 179200      activation_52[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)               (None, None, None, 16 179200      activation_57[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNor (None, None, None, 16 480         conv2d_53[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNor (None, None, None, 16 480         conv2d_58[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_53 (Activation)       (None, None, None, 16 0           batch_normalization_53[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_58 (Activation)       (None, None, None, 16 0           batch_normalization_58[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePool (None, None, None, 76 0           mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)               (None, None, None, 19 147456      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)               (None, None, None, 19 215040      activation_53[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)               (None, None, None, 19 215040      activation_58[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)               (None, None, None, 19 147456      average_pooling2d_6[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNor (None, None, None, 19 576         conv2d_51[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNor (None, None, None, 19 576         conv2d_54[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNor (None, None, None, 19 576         conv2d_59[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNor (None, None, None, 19 576         conv2d_60[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_51 (Activation)       (None, None, None, 19 0           batch_normalization_51[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_54 (Activation)       (None, None, None, 19 0           batch_normalization_54[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_59 (Activation)       (None, None, None, 19 0           batch_normalization_59[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_60 (Activation)       (None, None, None, 19 0           batch_normalization_60[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)             (None, None, None, 76 0           activation_51[0][0]              \n",
      "                                                                   activation_54[0][0]              \n",
      "                                                                   activation_59[0][0]              \n",
      "                                                                   activation_60[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)               (None, None, None, 19 147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNor (None, None, None, 19 576         conv2d_65[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_65 (Activation)       (None, None, None, 19 0           batch_normalization_65[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)               (None, None, None, 19 258048      activation_65[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNor (None, None, None, 19 576         conv2d_66[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_66 (Activation)       (None, None, None, 19 0           batch_normalization_66[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)               (None, None, None, 19 147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)               (None, None, None, 19 258048      activation_66[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNor (None, None, None, 19 576         conv2d_62[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNor (None, None, None, 19 576         conv2d_67[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_62 (Activation)       (None, None, None, 19 0           batch_normalization_62[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_67 (Activation)       (None, None, None, 19 0           batch_normalization_67[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)               (None, None, None, 19 258048      activation_62[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)               (None, None, None, 19 258048      activation_67[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNor (None, None, None, 19 576         conv2d_63[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNor (None, None, None, 19 576         conv2d_68[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_63 (Activation)       (None, None, None, 19 0           batch_normalization_63[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_68 (Activation)       (None, None, None, 19 0           batch_normalization_68[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePool (None, None, None, 76 0           mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)               (None, None, None, 19 147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)               (None, None, None, 19 258048      activation_63[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)               (None, None, None, 19 258048      activation_68[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)               (None, None, None, 19 147456      average_pooling2d_7[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNor (None, None, None, 19 576         conv2d_61[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNor (None, None, None, 19 576         conv2d_64[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNor (None, None, None, 19 576         conv2d_69[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNor (None, None, None, 19 576         conv2d_70[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_61 (Activation)       (None, None, None, 19 0           batch_normalization_61[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_64 (Activation)       (None, None, None, 19 0           batch_normalization_64[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_69 (Activation)       (None, None, None, 19 0           batch_normalization_69[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_70 (Activation)       (None, None, None, 19 0           batch_normalization_70[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)             (None, None, None, 76 0           activation_61[0][0]              \n",
      "                                                                   activation_64[0][0]              \n",
      "                                                                   activation_69[0][0]              \n",
      "                                                                   activation_70[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)               (None, None, None, 19 147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNor (None, None, None, 19 576         conv2d_73[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_73 (Activation)       (None, None, None, 19 0           batch_normalization_73[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)               (None, None, None, 19 258048      activation_73[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNor (None, None, None, 19 576         conv2d_74[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_74 (Activation)       (None, None, None, 19 0           batch_normalization_74[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)               (None, None, None, 19 147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)               (None, None, None, 19 258048      activation_74[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNor (None, None, None, 19 576         conv2d_71[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNor (None, None, None, 19 576         conv2d_75[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_71 (Activation)       (None, None, None, 19 0           batch_normalization_71[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_75 (Activation)       (None, None, None, 19 0           batch_normalization_75[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)               (None, None, None, 32 552960      activation_71[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)               (None, None, None, 19 331776      activation_75[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNor (None, None, None, 32 960         conv2d_72[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNor (None, None, None, 19 576         conv2d_76[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_72 (Activation)       (None, None, None, 32 0           batch_normalization_72[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_76 (Activation)       (None, None, None, 19 0           batch_normalization_76[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, None, None, 76 0           mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)             (None, None, None, 12 0           activation_72[0][0]              \n",
      "                                                                   activation_76[0][0]              \n",
      "                                                                   max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)               (None, None, None, 44 573440      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNor (None, None, None, 44 1344        conv2d_81[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_81 (Activation)       (None, None, None, 44 0           batch_normalization_81[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)               (None, None, None, 38 491520      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)               (None, None, None, 38 1548288     activation_81[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNor (None, None, None, 38 1152        conv2d_78[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNor (None, None, None, 38 1152        conv2d_82[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_78 (Activation)       (None, None, None, 38 0           batch_normalization_78[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_82 (Activation)       (None, None, None, 38 0           batch_normalization_82[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)               (None, None, None, 38 442368      activation_78[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)               (None, None, None, 38 442368      activation_78[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)               (None, None, None, 38 442368      activation_82[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)               (None, None, None, 38 442368      activation_82[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePool (None, None, None, 12 0           mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)               (None, None, None, 32 409600      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNor (None, None, None, 38 1152        conv2d_79[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNor (None, None, None, 38 1152        conv2d_80[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNor (None, None, None, 38 1152        conv2d_83[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNor (None, None, None, 38 1152        conv2d_84[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)               (None, None, None, 19 245760      average_pooling2d_8[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNor (None, None, None, 32 960         conv2d_77[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_79 (Activation)       (None, None, None, 38 0           batch_normalization_79[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_80 (Activation)       (None, None, None, 38 0           batch_normalization_80[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_83 (Activation)       (None, None, None, 38 0           batch_normalization_83[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_84 (Activation)       (None, None, None, 38 0           batch_normalization_84[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNor (None, None, None, 19 576         conv2d_85[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_77 (Activation)       (None, None, None, 32 0           batch_normalization_77[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)           (None, None, None, 76 0           activation_79[0][0]              \n",
      "                                                                   activation_80[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, None, None, 76 0           activation_83[0][0]              \n",
      "                                                                   activation_84[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_85 (Activation)       (None, None, None, 19 0           batch_normalization_85[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)             (None, None, None, 20 0           activation_77[0][0]              \n",
      "                                                                   mixed9_0[0][0]                   \n",
      "                                                                   concatenate_1[0][0]              \n",
      "                                                                   activation_85[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)               (None, None, None, 44 917504      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNor (None, None, None, 44 1344        conv2d_90[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_90 (Activation)       (None, None, None, 44 0           batch_normalization_90[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)               (None, None, None, 38 786432      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)               (None, None, None, 38 1548288     activation_90[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNor (None, None, None, 38 1152        conv2d_87[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNor (None, None, None, 38 1152        conv2d_91[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_87 (Activation)       (None, None, None, 38 0           batch_normalization_87[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_91 (Activation)       (None, None, None, 38 0           batch_normalization_91[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)               (None, None, None, 38 442368      activation_87[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)               (None, None, None, 38 442368      activation_87[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)               (None, None, None, 38 442368      activation_91[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)               (None, None, None, 38 442368      activation_91[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePool (None, None, None, 20 0           mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)               (None, None, None, 32 655360      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNor (None, None, None, 38 1152        conv2d_88[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNor (None, None, None, 38 1152        conv2d_89[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNor (None, None, None, 38 1152        conv2d_92[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNor (None, None, None, 38 1152        conv2d_93[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)               (None, None, None, 19 393216      average_pooling2d_9[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNor (None, None, None, 32 960         conv2d_86[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_88 (Activation)       (None, None, None, 38 0           batch_normalization_88[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_89 (Activation)       (None, None, None, 38 0           batch_normalization_89[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_92 (Activation)       (None, None, None, 38 0           batch_normalization_92[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_93 (Activation)       (None, None, None, 38 0           batch_normalization_93[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNor (None, None, None, 19 576         conv2d_94[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_86 (Activation)       (None, None, None, 32 0           batch_normalization_86[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)           (None, None, None, 76 0           activation_88[0][0]              \n",
      "                                                                   activation_89[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, None, None, 76 0           activation_92[0][0]              \n",
      "                                                                   activation_93[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_94 (Activation)       (None, None, None, 19 0           batch_normalization_94[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)            (None, None, None, 20 0           activation_86[0][0]              \n",
      "                                                                   mixed9_1[0][0]                   \n",
      "                                                                   concatenate_2[0][0]              \n",
      "                                                                   activation_94[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x7fac7bef7a90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the model we will train\n",
    "model = Model(base_model.input, predictions)\n",
    "#model.summary()\n",
    "model.layers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meme_path = '/media/backup/crawling/memes/meme_characters/'\n",
    "non_meme_path = '/media/backup/crawling/memes/test2014/'\n",
    "m_train, m_test, n_train, n_test = load_data(meme_path, non_meme_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training set\n",
    "x_train = np.vstack([m_train, n_train])\n",
    "my_train = np.ones((m_train.shape[0], 1))\n",
    "ny_train = np.zeros((n_train.shape[0], 1))\n",
    "y_train = to_categorical(np.vstack([my_train, ny_train]), num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validation set\n",
    "x_test = np.vstack([m_test, n_test])\n",
    "my_test = np.ones((m_test.shape[0], 1))\n",
    "ny_test = np.zeros((n_test.shape[0], 1))\n",
    "y_test = to_categorical(np.vstack([my_test, ny_test]), num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logdir = 'inception_log2.0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir=logdir, histogram_freq=1, write_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_datagen.flow(x_train, y_train, batch_size=32),\n",
    "                    samples_per_epoch = len(x_train) / 32,\n",
    "                    nb_epoch=80,\n",
    "                    callbacks=[tb],\n",
    "                    #initial_epoch=30,\n",
    "                    validation_data=test_datagen.flow(x_test, y_test, batch_size=32),\n",
    "                    nb_val_samples=1600 / 32)\n",
    "model.save(os.path.join(logdir, 'fine_inception.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(test_datagen.flow(x_test, y_test, batch_size=32), 32)\n",
    "print('score:', score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpudeepenv",
   "language": "python",
   "name": "cpudeepenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
