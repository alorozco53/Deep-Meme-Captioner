{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import configuration as config\n",
    "\n",
    "from utils.vocabulary import Vocabulary\n",
    "from utils.caption_generator import CaptionGenerator\n",
    "from model import MemeModel\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from utils.yanan_lm import text_processing, tokenize_unigram\n",
    "from utils.yanan_lm import unigram_V, unigrams_prob\n",
    "from utils.yanan_lm import ngram_prob, perplexity, add_k_smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Meme Captioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'model5.16/train/'\n",
    "vocab_file = 'batches/word_count.txt'\n",
    "dataset_dir = 'batches/part-0-to-11960/'\n",
    "model_file = 'small-conv/model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dataset_dir, image_format='jpeg'):\n",
    "    model = MemeModel('inference',\n",
    "                      vocab_file,\n",
    "                      model_file=model_file,\n",
    "                      dataset_dir=dataset_dir)\n",
    "    model.build(image_format)\n",
    "    return model\n",
    "\n",
    "def feed_image(sess, encoded_image):\n",
    "    initial_state = sess.run(fetches=\"lstm/initial_state:0\",\n",
    "                             feed_dict={\"image_feed:0\": encoded_image})\n",
    "    return initial_state\n",
    "\n",
    "def inference_step(sess, input_feed, state_feed):\n",
    "    softmax_output, state_output = sess.run(\n",
    "        fetches=[\"softmax:0\", \"lstm/state:0\"],\n",
    "        feed_dict={\n",
    "            \"input_feed:0\": input_feed,\n",
    "            \"lstm/state_feed:0\": state_feed,\n",
    "        })\n",
    "    return softmax_output, state_output, None\n",
    "\n",
    "# Creates a function that restores a model from checkpoint\n",
    "def create_restore_fn(checkpoint_path, saver):\n",
    "    if tf.gfile.IsDirectory(checkpoint_path):\n",
    "        checkpoint_path = tf.train.latest_checkpoint(checkpoint_path)\n",
    "        if not checkpoint_path:\n",
    "            raise ValueError(\"No checkpoint file found in: %s\" % checkpoint_path)\n",
    "\n",
    "    def _restore_fn(sess):\n",
    "        tf.logging.info(\"Loading model from checkpoint: %s\", checkpoint_path)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "        tf.logging.info(\"Successfully loaded checkpoint: %s\",\n",
    "                        os.path.basename(checkpoint_path))\n",
    "        \n",
    "    return _restore_fn\n",
    "\n",
    "# Builds the inference graph from a configuration object.\n",
    "def build_graph_from_config(data_dir, checkpoint_path, image_format='jpeg'):\n",
    "    tf.logging.info(\"Building model.\")\n",
    "    model = build_model(data_dir, image_format)\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    return create_restore_fn(checkpoint_path, saver), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model.\n",
      "Initializing the model's parameters...\n",
      "Mapping image embeddings...\n",
      "(1, 128)\n",
      "Building the LSTM model...\n",
      "(1, 100)\n",
      "Setting up the global step tensor...\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "restore_fn, mememodel = build_graph_from_config(dataset_dir,\n",
    "                                                checkpoint_path,\n",
    "                                                image_format='jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: batches/word_count.txt\n",
      "INFO:tensorflow:Created vocabulary with 7412 words\n"
     ]
    }
   ],
   "source": [
    "# Create the vocabulary.\n",
    "vocab = Vocabulary(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 146, 146, 16)      4624      \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "droput1 (Dropout)            (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 85264)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               10913920  \n",
      "_________________________________________________________________\n",
      "dropout3 (Dropout)           (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 10,919,440\n",
      "Trainable params: 10,919,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mememodel.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: model5.16/train/model.ckpt-2000000\n",
      "INFO:tensorflow:Restoring parameters from model5.16/train/model.ckpt-2000000\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt-2000000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "restore_fn(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = CaptionGenerator(feed_image, \n",
    "                             inference_step, \n",
    "                             vocab,\n",
    "                             max_caption_length=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Ngram tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = 'utils/brown.train.txt'\n",
    "unk_threshold = 5\n",
    "ADD_K_SMOOTHING = 'add_k_smoothing'\n",
    "LINER_INT = 'liner interpolation'\n",
    "NO_SMOOTHING = 'no smoothing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "train_text = text_processing(training_set)\n",
    "train_token = tokenize_unigram(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_count, replaced_tokens_train = unigram_V(train_token, unk_threshold)\n",
    "vocabulary = set(unigram_count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length 11331\n"
     ]
    }
   ],
   "source": [
    "# generate unigram probablity dict\n",
    "uni_prob_dict = {}\n",
    "uni_prob_dict = unigram_count.copy()\n",
    "unigrams_prob_dict = unigrams_prob(uni_prob_dict)\n",
    "\n",
    "V = len(vocabulary)\n",
    "print(\"Vocabulary length\", V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate trigram probability dict\n",
    "trigram_prob_dict = ngram_prob(3, replaced_tokens_train, unigram_count)\n",
    "\n",
    "# generate bigram probability dict\n",
    "bigram_prob_dict = ngram_prob(2, replaced_tokens_train, unigram_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caption pre-processing\n",
    "def text_processing(text, STOP_token='_STOP_'):\n",
    "    txt = text.replace('\\n',' '+STOP_token+'\\n')\n",
    "    puncts = '!\"#$%&()*+,-./:;<=>?@[\\\\]^`{|}~'\n",
    "    for p in puncts:\n",
    "        txt = txt.replace(p, ' ')\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caption and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaldataset/no_memes/COCO_test2014_000000437409.jpg \n",
      " ask ask ask burnt seats fora\n",
      "ask ask ask burnt burnt seats\n",
      "ask ask ask burnt burnt fora\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000437409.jpg\"> | ask ask ask burnt seats fora / 1751.52 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000581919.jpg \n",
      " musica musica starve victoria victoria victoria\n",
      "musica musica musica victoria victoria victoria\n",
      "musica musica musica starve victoria victoria\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000581919.jpg\"> | musica musica starve victoria victoria victoria / 1751.52 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000437984.jpg \n",
      " facebook facebook 100000 100000 100000 matter\n",
      "facebook facebook 100000 100000 100000 100000\n",
      "facebook facebook 100000 100000 100000 maldita\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000437984.jpg\"> | facebook facebook 100000 100000 100000 matter / 1751.52 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000581911.jpg \n",
      " kanji kanji matter matter matter matter\n",
      "kanji kanji matter matter matter matter\n",
      "quieres kanji matter matter matter matter\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000581911.jpg\"> | kanji kanji matter matter matter matter / 80.89 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000291121.jpg \n",
      " 100000 100000 100000 fanfic 500 500\n",
      "100000 100000 100000 100000 500 500\n",
      "100000 100000 100000 100000 fanfic 500\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000291121.jpg\"> | 100000 100000 100000 fanfic 500 500 / 1751.52 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000581645.jpg \n",
      " already already already already already already\n",
      "already already already already already ancestors\n",
      "already already already already already ancestors\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000581645.jpg\"> | already already already already already already / 80.89 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000437560.jpg \n",
      " construct construct construct construct construct matter\n",
      "construct construct construct construct matter matter\n",
      "invisible construct construct construct construct matter\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000437560.jpg\"> | construct construct construct construct construct matter / 1751.52 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000438020.jpg \n",
      " deaths news news news news news\n",
      "deaths news news news news news\n",
      "deaths news news news news 2000\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000438020.jpg\"> | deaths news news news news news / 80.89 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000581923.jpg \n",
      " compared compared compared compared compared compared\n",
      "compared compared compared compared compared movie\n",
      "compared compared compared compared compared movie\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000581923.jpg\"> | compared compared compared compared compared compared / 80.89 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000291429.jpg \n",
      " epic epic settle settle dwarf settle\n",
      "epic epic settle settle dwarf settle\n",
      "epic epic settle settle dwarf settle\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000291429.jpg\"> | epic epic settle settle dwarf settle / 7.14 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000145319.jpg \n",
      " direct direct 100000 100000 100000 compared\n",
      "direct 100000 100000 100000 100000 chores\n",
      "direct direct 100000 100000 100000 compared\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000145319.jpg\"> | direct direct 100000 100000 100000 compared / 80.89 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000438022.jpg \n",
      " already already already already ancestors ancestors\n",
      "already already already already ancestors poring\n",
      "already already already already ancestors ancestors\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000438022.jpg\"> | already already already already ancestors ancestors / 80.89 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000145729.jpg \n",
      " sick sir sir sir sir sir\n",
      "sir sir sir sir sir sir\n",
      "sick sir sir sir sir sir\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000145729.jpg\"> | sick sir sir sir sir sir / 80.89 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000145754.jpg \n",
      " wrestle wrestle wrestle wrestle compared compared\n",
      "wrestle wrestle wrestle wrestle compared compared\n",
      "wrestle wrestle wrestle parked compared compared\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000145754.jpg\"> | wrestle wrestle wrestle wrestle compared compared / 80.89 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000145275.jpg \n",
      " winner winner maldita maldita burnt african\n",
      "winner winner maldita maldita maldita burnt\n",
      "winner winner maldita maldita burnt maldita\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000145275.jpg\"> | winner winner maldita maldita burnt african / 1751.52 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000291015.jpg \n",
      " movie movie movie movie spiders spiders\n",
      "movie movie movie spiders spiders spiders\n",
      "movie movie movie movie movie spiders\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000291015.jpg\"> | movie movie movie movie spiders spiders / 1751.52 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000145756.jpg \n",
      " compared compared compared compared compared compared\n",
      "compared compared compared compared compared compared\n",
      "compared compared compared compared compared wrestle\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000145756.jpg\"> | compared compared compared compared compared compared / 80.89 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000581585.jpg \n",
      " fanfic fanfic fanfic fanfic fanfic ver\n",
      "fanfic fanfic fanfic fanfic leaves ver\n",
      "fanfic fanfic fanfic fanfic fanfic ver\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000581585.jpg\"> | fanfic fanfic fanfic fanfic fanfic ver / 80.89 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000291434.jpg \n",
      " gordo cameron stfu stfu stfu park\n",
      "cameron stfu stfu stfu stfu park\n",
      "cameron cameron stfu stfu stfu park\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000291434.jpg\"> | gordo cameron stfu stfu stfu park / 1751.52 |  |\n",
      "\n",
      "evaldataset/no_memes/COCO_test2014_000000291423.jpg \n",
      " direct direct direct fanfic fanfic thru\n",
      "direct direct fanfic fanfic thru thru\n",
      "direct direct direct fanfic thru thru\n",
      "\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000291423.jpg\"> | direct direct direct fanfic fanfic thru / 1751.52 |  |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testdir = 'evaldataset/no_memes/'\n",
    "testdir = [os.path.join(testdir, t) for t in os.listdir(testdir)]\n",
    "k_ls = (0.0000001,0.000001,0.00001,0.0001,0.01,0.1,1)\n",
    "basestring = '| <img width=\"50\" alt=\"50\" src=\"{}\"> | {} / {:.2f} |  |'\n",
    "for filename in testdir:\n",
    "    if os.path.exists(filename):\n",
    "        # Caption image\n",
    "        img = image.load_img(filename, target_size=(150, 150))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        preds = mememodel.model.predict(x)\n",
    "        captions = generator.beam_search(sess, preds)\n",
    "        candidates = ''\n",
    "        output = ''\n",
    "        for i, caption in enumerate(captions):\n",
    "            cap = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n",
    "            cap = ' '.join(cap)\n",
    "            if i == 0:\n",
    "                output = cap\n",
    "            candidates += cap + '\\n'\n",
    "        print(filename, '\\n', candidates)\n",
    "        dev_text = text_processing(candidates)\n",
    "        perps = 0\n",
    "        for k in k_ls:\n",
    "            tri_addk_prob_dict = add_k_smoothing(3, replaced_tokens_train, unigram_count, k, V)\n",
    "            perps += perplexity(dev_text,3,tri_addk_prob_dict,ADD_K_SMOOTHING)\n",
    "        print(basestring.format(filename, output, perps / len(k_ls)), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13434.24'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:.2f}'.format(13434.23949)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Imagen | Leyenda Modelo A / Perplejidad   | Leyenda Modelo B / Perplejidad |\n",
    "|:------:|:----------------:|:-------------:|\n",
    "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/20.jpg\"> | brownies brownies brownies brownies church shake / 80.88927376112007 | fuck off |\n",
    "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/12.png.jpg\"> | lucky rush rush rush rush rush / 80.88927376112007 | fuck off |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Imagen | Leyenda Modelo `A` / Perplejidad  | Leyenda Modelo `B` / Perplejidad |\n",
    "|:------:|:----------------:|:-------------:|\n",
    "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000437409.jpg\"> | ask ask ask burnt seats fora / 1751.52 |  |\n",
    "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000581919.jpg\"> | musica musica starve victoria victoria victoria / 1751.52 |  |\n",
    "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000437984.jpg\"> | facebook facebook 100000 100000 100000 matter / 1751.52 |  |\n",
    "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000581911.jpg\"> | kanji kanji matter matter matter matter / 80.89 |  |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpudeepenv",
   "language": "python",
   "name": "cpudeepenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
