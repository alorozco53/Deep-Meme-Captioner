{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import configuration as config\n",
    "\n",
    "from utils.vocabulary import Vocabulary\n",
    "from utils.caption_generator import CaptionGenerator\n",
    "from model import MemeModel\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from utils.yanan_lm import text_processing, tokenize_unigram\n",
    "from utils.yanan_lm import unigram_V, unigrams_prob\n",
    "from utils.yanan_lm import ngram_prob, perplexity, add_k_smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Meme Captioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'model5.12/train/'\n",
    "vocab_file = 'batches/word_count.txt'\n",
    "dataset_dir = 'batches/part-0-to-11960/'\n",
    "model_file = 'small-conv/model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model('/media/memes/inception_log3.0/fine_inception.h5')\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dataset_dir, image_format='jpeg'):\n",
    "    model = MemeModel('inference',\n",
    "                      vocab_file,\n",
    "                      model_file=model_file,\n",
    "                      dataset_dir=dataset_dir)\n",
    "    model.build(image_format)\n",
    "    return model\n",
    "\n",
    "def feed_image(sess, encoded_image):\n",
    "    initial_state = sess.run(fetches=\"lstm/initial_state:0\",\n",
    "                             feed_dict={\"image_feed:0\": encoded_image})\n",
    "    return initial_state\n",
    "\n",
    "def inference_step(sess, input_feed, state_feed):\n",
    "    softmax_output, state_output = sess.run(\n",
    "        fetches=[\"softmax:0\", \"lstm/state:0\"],\n",
    "        feed_dict={\n",
    "            \"input_feed:0\": input_feed,\n",
    "            \"lstm/state_feed:0\": state_feed,\n",
    "        })\n",
    "    return softmax_output, state_output, None\n",
    "\n",
    "# Creates a function that restores a model from checkpoint\n",
    "def create_restore_fn(checkpoint_path, saver):\n",
    "    if tf.gfile.IsDirectory(checkpoint_path):\n",
    "        checkpoint_path = tf.train.latest_checkpoint(checkpoint_path)\n",
    "        if not checkpoint_path:\n",
    "            raise ValueError(\"No checkpoint file found in: %s\" % checkpoint_path)\n",
    "\n",
    "    def _restore_fn(sess):\n",
    "        tf.logging.info(\"Loading model from checkpoint: %s\", checkpoint_path)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "        tf.logging.info(\"Successfully loaded checkpoint: %s\",\n",
    "                        os.path.basename(checkpoint_path))\n",
    "        \n",
    "    return _restore_fn\n",
    "\n",
    "# Builds the inference graph from a configuration object.\n",
    "def build_graph_from_config(data_dir, checkpoint_path, image_format='jpeg'):\n",
    "    tf.logging.info(\"Building model.\")\n",
    "    model = build_model(data_dir, image_format)\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    return create_restore_fn(checkpoint_path, saver), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model.\n",
      "Initializing the model's parameters...\n",
      "Mapping image embeddings...\n",
      "(1, 128)\n",
      "Building the LSTM model...\n",
      "(1, 100)\n",
      "Setting up the global step tensor...\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "restore_fn, mememodel = build_graph_from_config(dataset_dir,\n",
    "                                                checkpoint_path,\n",
    "                                                image_format='jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: batches/word_count.txt\n",
      "INFO:tensorflow:Created vocabulary with 7412 words\n"
     ]
    }
   ],
   "source": [
    "# Create the vocabulary.\n",
    "vocab = Vocabulary(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 146, 146, 16)      4624      \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "droput1 (Dropout)            (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 85264)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               10913920  \n",
      "_________________________________________________________________\n",
      "dropout3 (Dropout)           (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 10,919,440\n",
      "Trainable params: 10,919,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mememodel.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: model5.12/train/model.ckpt-1000000\n",
      "INFO:tensorflow:Restoring parameters from model5.12/train/model.ckpt-1000000\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt-1000000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "restore_fn(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = CaptionGenerator(feed_image, \n",
    "                             inference_step, \n",
    "                             vocab,\n",
    "                             max_caption_length=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Ngram tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = 'evaldataset/meme.train.txt'\n",
    "unk_threshold = 5\n",
    "ADD_K_SMOOTHING = 'add_k_smoothing'\n",
    "LINER_INT = 'liner interpolation'\n",
    "NO_SMOOTHING = 'no smoothing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "train_text = text_processing(training_set)\n",
    "train_token = tokenize_unigram(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_count, replaced_tokens_train = unigram_V(train_token, unk_threshold)\n",
    "vocabulary = set(unigram_count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length 5722\n"
     ]
    }
   ],
   "source": [
    "# generate unigram probablity dict\n",
    "uni_prob_dict = {}\n",
    "uni_prob_dict = unigram_count.copy()\n",
    "unigrams_prob_dict = unigrams_prob(uni_prob_dict)\n",
    "\n",
    "V = len(vocabulary)\n",
    "print(\"Vocabulary length\", V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate trigram probability dict\n",
    "trigram_prob_dict = ngram_prob(3, replaced_tokens_train, unigram_count)\n",
    "\n",
    "# generate bigram probability dict\n",
    "bigram_prob_dict = ngram_prob(2, replaced_tokens_train, unigram_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caption pre-processing\n",
    "def text_processing(text, STOP_token='_STOP_'):\n",
    "    txt = text.replace('\\n',' '+STOP_token+'\\n')\n",
    "    puncts = '!\"#$%&()*+,-./:;<=>?@[\\\\]^`{|}~'\n",
    "    for p in puncts:\n",
    "        txt = txt.replace(p, ' ')\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caption and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaldataset/new_memes/12.png.jpg twat bigbangtheory bigbangtheory bigbangtheory bigbangtheory bigbangtheory / 58.65\n",
      "evaldataset/new_memes/1.jpg neighbors neighbors neighbors puto afternoon afternoon / 1014.00\n",
      "evaldataset/new_memes/18.png escort escort escort escort escort escort / 58.65\n",
      "evaldataset/new_memes/5.jpg count count count count legalize legalize / 6.18\n",
      "evaldataset/new_memes/11.png.jpg verga verga verga verga kisses читать / 58.65\n",
      "evaldataset/new_memes/6.jpg bangga tapi rise ref universal universal / 58.65\n",
      "evaldataset/new_memes/8.jpg reported reported anonymous duke everytime everytime / 1014.00\n",
      "evaldataset/new_memes/9.png.jpg marco marco nach nach truth truth / 58.65\n",
      "evaldataset/new_memes/19.png meet meet meet gerd gerd calvin / 1014.00\n",
      "evaldataset/new_memes/3.jpg touch je je je je je / 58.65\n",
      "evaldataset/new_memes/17.png theory theory theory sales sales sales / 1014.00\n",
      "evaldataset/new_memes/20.png gunna gunna gunna gunna not afternoon / 58.65\n",
      "evaldataset/new_memes/15.png.jpg reported reported patient patient patient patient / 6.18\n",
      "evaldataset/new_memes/13.png.jpg main chemicals chemicals connected connected connected / 58.65\n",
      "evaldataset/new_memes/10.png.jpg theory theory theory theory theory attractive / 6.18\n",
      "evaldataset/new_memes/4.jpg iq iq iq iq iq corporate / 58.65\n",
      "evaldataset/new_memes/14.png.jpg dicen dicen dicen belong belong biology / 58.65\n",
      "evaldataset/new_memes/2.png.jpg saint saint saint brains brains brains / 6.18\n",
      "evaldataset/new_memes/7.png.jpg theory theory theory theory meet robert / 58.65\n",
      "evaldataset/new_memes/16.jpg scary scary xbox xbox xbox xbox / 6.18\n",
      "total avg: 236.60215932980086\n"
     ]
    }
   ],
   "source": [
    "testdir = 'evaldataset/new_memes/'\n",
    "testdir = [os.path.join(testdir, t) for t in os.listdir(testdir)]\n",
    "k_ls = (0.0000001,0.000001,0.00001,0.0001,0.01,0.1,1)\n",
    "basestring = '{} / {:.2f}'\n",
    "\n",
    "count = 0\n",
    "for filename in testdir:\n",
    "    if os.path.exists(filename):\n",
    "        # Caption image\n",
    "        img = image.load_img(filename, target_size=(150, 150))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        preds = mememodel.model.predict(x)\n",
    "        captions = generator.beam_search(sess, preds)\n",
    "        candidates = ''\n",
    "        output = ''\n",
    "        for i, caption in enumerate(captions):\n",
    "            cap = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n",
    "            cap = ' '.join(cap)\n",
    "            if i == 0:\n",
    "                output = cap\n",
    "            candidates += cap + '\\n'\n",
    "        dev_text = text_processing(candidates)\n",
    "        perps = 0\n",
    "        for k in k_ls:\n",
    "            tri_addk_prob_dict = add_k_smoothing(3, replaced_tokens_train, unigram_count, k, V)\n",
    "            perps += perplexity(dev_text,3,tri_addk_prob_dict,ADD_K_SMOOTHING)\n",
    "        count += (perps / len(k_ls))\n",
    "        print(filename, basestring.format(output, perps / len(k_ls)))\n",
    "print('total avg:', count / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaldataset/old_memes/20.jpg frat frat hiatus hiatus eh eh / 6.18\n",
      "evaldataset/old_memes/10.jpg notice touch ahead ahead ahead ahead / 75.64\n",
      "evaldataset/old_memes/12.jpg jackass conditions conditions conditions calvin calvin / 58.65\n",
      "evaldataset/old_memes/1.jpg tower ahead ahead gerd ahead gerd / 1014.00\n",
      "evaldataset/old_memes/7.jpg spock spock spock afternoon afternoon afternoon / 1014.00\n",
      "evaldataset/old_memes/5.jpg dances pvp pvp pvp mine pvp / 554.64\n",
      "evaldataset/old_memes/18.jpg feet feet wait rails rails rails / 58.65\n",
      "evaldataset/old_memes/6.jpg feelings feelings feelings feelings forgive forgive / 58.65\n",
      "evaldataset/old_memes/14.jpg teachers teachers teachers teachers teachers teachers / 58.65\n",
      "evaldataset/old_memes/13.jpg grandma grandma grandma grandma grandma grandma / 58.65\n",
      "evaldataset/old_memes/15.jpg wished wished wished peyton peyton rustled / 58.65\n",
      "evaldataset/old_memes/2.jpg 4s 4s 4s 4s bronze bronze / 58.65\n",
      "evaldataset/old_memes/8.jpg pt pt pt pt clothes clothes / 1014.00\n",
      "evaldataset/old_memes/9.jpg odds odds odds odds odds odds / 58.65\n",
      "evaldataset/old_memes/3.jpg symptoms symptoms symptoms symptoms symptoms symptoms / 6.18\n",
      "evaldataset/old_memes/11.jpg kisses kisses killing killing killing killing / 6.18\n",
      "evaldataset/old_memes/17.jpg meet ahead ahead ahead ahead ahead / 58.65\n",
      "evaldataset/old_memes/4.jpg tower tower armor teachers teachers kept / 58.65\n",
      "evaldataset/old_memes/19.jpg feelings feelings starved starved starved starved / 1014.00\n",
      "evaldataset/old_memes/16.jpg biology biology biology gain gain gain / 58.65\n",
      "total avg: 267.4980197126502\n"
     ]
    }
   ],
   "source": [
    "testdir = 'evaldataset/old_memes/'\n",
    "testdir = [os.path.join(testdir, t) for t in os.listdir(testdir)]\n",
    "k_ls = (0.0000001,0.000001,0.00001,0.0001,0.01,0.1,1)\n",
    "basestring = '{} / {:.2f}'\n",
    "\n",
    "count = 0\n",
    "for filename in testdir:\n",
    "    if os.path.exists(filename):\n",
    "        # Caption image\n",
    "        img = image.load_img(filename, target_size=(150, 150))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        preds = mememodel.model.predict(x)\n",
    "        captions = generator.beam_search(sess, preds)\n",
    "        candidates = ''\n",
    "        output = ''\n",
    "        for i, caption in enumerate(captions):\n",
    "            cap = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n",
    "            cap = ' '.join(cap)\n",
    "            if i == 0:\n",
    "                output = cap\n",
    "            candidates += cap + '\\n'\n",
    "        dev_text = text_processing(candidates)\n",
    "        perps = 0\n",
    "        for k in k_ls:\n",
    "            tri_addk_prob_dict = add_k_smoothing(3, replaced_tokens_train, unigram_count, k, V)\n",
    "            perps += perplexity(dev_text,3,tri_addk_prob_dict,ADD_K_SMOOTHING)\n",
    "        count += (perps / len(k_ls))\n",
    "        print(filename, basestring.format(output, perps / len(k_ls)))\n",
    "print('total avg:', count / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaldataset/no_memes/COCO_test2014_000000437409.jpg queue queue queue queue je cultural / 58.65\n",
      "evaldataset/no_memes/COCO_test2014_000000581919.jpg tower tower tower sort sort reaction / 58.65\n",
      "evaldataset/no_memes/COCO_test2014_000000437984.jpg shizzle argument argument argument argument argument / 6.18\n",
      "evaldataset/no_memes/COCO_test2014_000000581911.jpg choir choir choir choir sandy calvin / 1014.00\n",
      "evaldataset/no_memes/COCO_test2014_000000291121.jpg accept theory theory theory nach admit / 58.65\n",
      "evaldataset/no_memes/COCO_test2014_000000581645.jpg nach nach nach not not not / 1014.00\n",
      "evaldataset/no_memes/COCO_test2014_000000437560.jpg armor armor armor wished jeans jeans / 58.65\n",
      "evaldataset/no_memes/COCO_test2014_000000438020.jpg bangga bangga fps fps fps fps / 58.65\n",
      "evaldataset/no_memes/COCO_test2014_000000581923.jpg jacket since since since since since / 58.65\n",
      "evaldataset/no_memes/COCO_test2014_000000291429.jpg memegeneratornet memegeneratornet memegeneratornet memegeneratornet memegeneratornet memegeneratornet / 58.65\n",
      "evaldataset/no_memes/COCO_test2014_000000145319.jpg forgive forgive forgive forgive forgive forgive / 58.65\n",
      "evaldataset/no_memes/COCO_test2014_000000438022.jpg didnt grandma ahead ahead ahead ahead / 6.18\n",
      "evaldataset/no_memes/COCO_test2014_000000145729.jpg since since since since mo mo / 1014.00\n",
      "evaldataset/no_memes/COCO_test2014_000000145754.jpg gain gain gain gain gain gain / 58.65\n",
      "evaldataset/no_memes/COCO_test2014_000000145275.jpg adorable cats not not not not / 6.18\n",
      "evaldataset/no_memes/COCO_test2014_000000291015.jpg mission mission mission mission mission mission / 58.65\n",
      "evaldataset/no_memes/COCO_test2014_000000145756.jpg tara tara tara symptoms symptoms gerd / 6.18\n",
      "evaldataset/no_memes/COCO_test2014_000000581585.jpg theory theory theory jennifer jennifer tour / 6.18\n",
      "evaldataset/no_memes/COCO_test2014_000000291434.jpg one's one's one's afterwards afterwards case / 1940.24\n",
      "evaldataset/no_memes/COCO_test2014_000000291423.jpg yourself yourself dammit dammit dammit dammit / 58.65\n",
      "total avg: 282.91387937532494\n"
     ]
    }
   ],
   "source": [
    "testdir = 'evaldataset/no_memes/'\n",
    "testdir = [os.path.join(testdir, t) for t in os.listdir(testdir)]\n",
    "k_ls = (0.0000001,0.000001,0.00001,0.0001,0.01,0.1,1)\n",
    "basestring = '{} / {:.2f}'\n",
    "\n",
    "count = 0\n",
    "for filename in testdir:\n",
    "    if os.path.exists(filename):\n",
    "        # Caption image\n",
    "        img = image.load_img(filename, target_size=(150, 150))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        preds = mememodel.model.predict(x)\n",
    "        captions = generator.beam_search(sess, preds)\n",
    "        candidates = ''\n",
    "        output = ''\n",
    "        for i, caption in enumerate(captions):\n",
    "            cap = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n",
    "            cap = ' '.join(cap)\n",
    "            if i == 0:\n",
    "                output = cap\n",
    "            candidates += cap + '\\n'\n",
    "        dev_text = text_processing(candidates)\n",
    "        perps = 0\n",
    "        for k in k_ls:\n",
    "            tri_addk_prob_dict = add_k_smoothing(3, replaced_tokens_train, unigram_count, k, V)\n",
    "            perps += perplexity(dev_text,3,tri_addk_prob_dict,ADD_K_SMOOTHING)\n",
    "        count += (perps / len(k_ls))\n",
    "        print(filename, basestring.format(output, perps / len(k_ls)))\n",
    "print('total avg:', count / 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Datos | Perplejidad promedio vs corpus evaluación, Modelo `A` | Perplejidad promedio vs corpus evaluación, Modelo `B` |\n",
    "|------:|:----------------:|:---------:|\n",
    "| Nuevos Memes | 331.14 | 74.66 |\n",
    "| Memes Evaluación | 241.78 | 47.19 |\n",
    "| No Memes | 342.68 | 30.17 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Imagen | Leyenda Modelo `A` / Perplejidad  | Leyenda Modelo `B` / Perplejidad |\n",
    "|:------:|:----------------:|:-------------:|\n",
    "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000437409.jpg\"> | ask ask ask burnt seats fora / 1751.52 |  |\n",
    "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000581919.jpg\"> | musica musica starve victoria victoria victoria / 1751.52 |  |\n",
    "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000437984.jpg\"> | facebook facebook 100000 100000 100000 matter / 1751.52 |  |\n",
    "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000581911.jpg\"> | kanji kanji matter matter matter matter / 80.89 |  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Imagen | Leyenda 1 | Leyenda 2 | Leyenda 3 |\n",
    "|:------:|:----------------:|:-------------:|:-------------:|\n",
    "| <img width=\"150\" alt=\"200\" src=\"sample/one-does-not-simply.jpg\"> | one does not simply have one | one does not simply have a meme | one does not simply have one one |\n",
    "| <img width=\"150\" alt=\"200\" src=\"sample/bender.jpg\"> | i got a meme | i have a meme | i am a good |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Imagen | Leyenda 1 | Leyenda 2 | Leyenda 3 |\n",
    "|:------:|:----------------:|:-------------:|:-------------:|\n",
    "| <img width=\"150\" alt=\"200\" src=\"test/cat_eyes.jpg\"> | thesis thesis thesis thesis tony banner banner banner | thesis thesis thesis thesis tony banner banner banner | thesis thesis thesis thesis banner tony banner banner |\n",
    "| <img width=\"150\" alt=\"200\" src=\"sample/guy-bathroom.jpg\"> | imperialist imperialist imperialist gates gates attack | imperialist imperialist imperialist gates gates chad | imperialist imperialist imperialist gates attack chad |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Imagen | Leyenda 1 | Leyenda 2 | Leyenda 3 |\n",
    "|:------:|:----------------:|:-------------:|:-------------:|\n",
    "| <img width=\"150\" alt=\"200\" src=\"test/cat_eyes.jpg\"> | trains trains trains trains trains carefully | otrains trains trains trains carefully carefully | trains trains trains trains trains carefully |\n",
    "| <img width=\"150\" alt=\"200\" src=\"sample/bender.jpg\"> | kurt virgin born doing bed bed dreams dreams | kurt virgin born doing bed bed chill confused | kurt virgin born doing bed bed dreams dreams |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Imagen | Leyenda 1 | Leyenda 2 | Leyenda 3 |\n",
    "|:------:|:----------------:|:-------------:|:-------------:|\n",
    "| <img width=\"150\" alt=\"100\" src=\"sample/es-bakans.jpg\"> | blacks trade vacation vs pure pure | blacks trade vacation vacation pure pure | blacks trade vacation vs pure magic |\n",
    "| <img width=\"150\" alt=\"200\" src=\"sample/bender.jpg\"> | avoid avoid surrender easily easily easily | avoid avoid surrender easily easily easily | avoid avoid avoid surrender easily easily |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpudeepenv",
   "language": "python",
   "name": "cpudeepenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
