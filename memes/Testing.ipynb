{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import configuration as config\n",
    "\n",
    "from utils.vocabulary import Vocabulary\n",
    "from utils.caption_generator import CaptionGenerator\n",
    "from model import MemeModel\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from utils.yanan_lm import text_processing, tokenize_unigram\n",
    "from utils.yanan_lm import unigram_V, unigrams_prob\n",
    "from utils.yanan_lm import ngram_prob, perplexity, add_k_smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Meme Captioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'model5.16/train/'\n",
    "vocab_file = 'batches/word_count.txt'\n",
    "dataset_dir = 'batches/part-0-to-11960/'\n",
    "model_file = 'small-conv/model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dataset_dir, image_format='jpeg'):\n",
    "    model = MemeModel('inference',\n",
    "                      vocab_file,\n",
    "                      model_file=model_file,\n",
    "                      dataset_dir=dataset_dir)\n",
    "    model.build(image_format)\n",
    "    return model\n",
    "\n",
    "def feed_image(sess, encoded_image):\n",
    "    initial_state = sess.run(fetches=\"lstm/initial_state:0\",\n",
    "                             feed_dict={\"image_feed:0\": encoded_image})\n",
    "    return initial_state\n",
    "\n",
    "def inference_step(sess, input_feed, state_feed):\n",
    "    softmax_output, state_output = sess.run(\n",
    "        fetches=[\"softmax:0\", \"lstm/state:0\"],\n",
    "        feed_dict={\n",
    "            \"input_feed:0\": input_feed,\n",
    "            \"lstm/state_feed:0\": state_feed,\n",
    "        })\n",
    "    return softmax_output, state_output, None\n",
    "\n",
    "# Creates a function that restores a model from checkpoint\n",
    "def create_restore_fn(checkpoint_path, saver):\n",
    "    if tf.gfile.IsDirectory(checkpoint_path):\n",
    "        checkpoint_path = tf.train.latest_checkpoint(checkpoint_path)\n",
    "        if not checkpoint_path:\n",
    "            raise ValueError(\"No checkpoint file found in: %s\" % checkpoint_path)\n",
    "\n",
    "    def _restore_fn(sess):\n",
    "        tf.logging.info(\"Loading model from checkpoint: %s\", checkpoint_path)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "        tf.logging.info(\"Successfully loaded checkpoint: %s\",\n",
    "                        os.path.basename(checkpoint_path))\n",
    "        \n",
    "    return _restore_fn\n",
    "\n",
    "# Builds the inference graph from a configuration object.\n",
    "def build_graph_from_config(data_dir, checkpoint_path, image_format='jpeg'):\n",
    "    tf.logging.info(\"Building model.\")\n",
    "    model = build_model(data_dir, image_format)\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    return create_restore_fn(checkpoint_path, saver), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model.\n",
      "Initializing the model's parameters...\n",
      "Mapping image embeddings...\n",
      "(1, 128)\n",
      "Building the LSTM model...\n",
      "(1, 100)\n",
      "Setting up the global step tensor...\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "restore_fn, mememodel = build_graph_from_config(dataset_dir,\n",
    "                                                checkpoint_path,\n",
    "                                                image_format='jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: batches/word_count.txt\n",
      "INFO:tensorflow:Created vocabulary with 7412 words\n"
     ]
    }
   ],
   "source": [
    "# Create the vocabulary.\n",
    "vocab = Vocabulary(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 146, 146, 16)      4624      \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "droput1 (Dropout)            (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 85264)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               10913920  \n",
      "_________________________________________________________________\n",
      "dropout3 (Dropout)           (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 10,919,440\n",
      "Trainable params: 10,919,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mememodel.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: model5.16/train/model.ckpt-2000000\n",
      "INFO:tensorflow:Restoring parameters from model5.16/train/model.ckpt-2000000\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt-2000000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "restore_fn(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = CaptionGenerator(feed_image, \n",
    "                             inference_step, \n",
    "                             vocab,\n",
    "                             max_caption_length=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Ngram tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = 'evaldataset/meme.train.txt'\n",
    "unk_threshold = 5\n",
    "ADD_K_SMOOTHING = 'add_k_smoothing'\n",
    "LINER_INT = 'liner interpolation'\n",
    "NO_SMOOTHING = 'no smoothing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "train_text = text_processing(training_set)\n",
    "train_token = tokenize_unigram(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_count, replaced_tokens_train = unigram_V(train_token, unk_threshold)\n",
    "vocabulary = set(unigram_count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length 5722\n"
     ]
    }
   ],
   "source": [
    "# generate unigram probablity dict\n",
    "uni_prob_dict = {}\n",
    "uni_prob_dict = unigram_count.copy()\n",
    "unigrams_prob_dict = unigrams_prob(uni_prob_dict)\n",
    "\n",
    "V = len(vocabulary)\n",
    "print(\"Vocabulary length\", V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate trigram probability dict\n",
    "trigram_prob_dict = ngram_prob(3, replaced_tokens_train, unigram_count)\n",
    "\n",
    "# generate bigram probability dict\n",
    "bigram_prob_dict = ngram_prob(2, replaced_tokens_train, unigram_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caption pre-processing\n",
    "def text_processing(text, STOP_token='_STOP_'):\n",
    "    txt = text.replace('\\n',' '+STOP_token+'\\n')\n",
    "    puncts = '!\"#$%&()*+,-./:;<=>?@[\\\\]^`{|}~'\n",
    "    for p in puncts:\n",
    "        txt = txt.replace(p, ' ')\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caption and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/20.jpg\"> | evolution approval approval approval approval approval / 58.65 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/12.png.jpg\"> | professor theory grandpa grandpa studio studio / 58.65 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/1.jpg\"> | statue then then laughter laughter laughter / 6.18 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/5.jpg\"> | cant equally equally shit shit shit / 232.72 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/11.png.jpg\"> | wrapped wrapped wrapped wrapped wrapped wrapped / 6.18 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/18.jpg\"> | approval approval approval lincoln lincoln lincoln / 58.65 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/6.jpg\"> | unlock unlock unlock unlock pleased restart / 58.65 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/8.jpg\"> | freeze freeze stranger boss laughter laughter / 6.18 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/9.png.jpg\"> | wrapped wrapped wrapped wrapped wrapped wrapped / 6.18 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/3.jpg\"> | approval approval approval approval approval approval / 6.18 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/17.jpg\"> | scorpion something something something something something / 19.24 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/15.png.jpg\"> | paga paga paga paga paga paga / 6.18 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/13.png.jpg\"> | visit something something something something signed / 58.65 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/10.png.jpg\"> | genocide genocide genocide unlock unlock warfare / 1014.00 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/4.jpg\"> | pops pops pops pops equally elephant / 58.65 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/19.jpg\"> | jazz jazz occupied occupied occupied occupied / 58.65 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/14.png.jpg\"> | wrapped wrapped wrapped wrapped wrapped wrapped / 58.65 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/2.png.jpg\"> | wrapped wrapped wrapped wrapped wrapped shit / 1014.00 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/7.png.jpg\"> | freeze freeze shit shit shit shit / 232.72 |  |\n",
      "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/16.jpg\"> | approval approval approval approval approval approval / 58.65 |  |\n"
     ]
    }
   ],
   "source": [
    "testdir = 'evaldataset/memes/'\n",
    "testdir = [os.path.join(testdir, t) for t in os.listdir(testdir)]\n",
    "k_ls = (0.0000001,0.000001,0.00001,0.0001,0.01,0.1,1)\n",
    "basestring = '| <img width=\"50\" alt=\"50\" src=\"{}\"> | {} / {:.2f} |  |'\n",
    "for filename in testdir:\n",
    "    if os.path.exists(filename):\n",
    "        # Caption image\n",
    "        img = image.load_img(filename, target_size=(150, 150))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        preds = mememodel.model.predict(x)\n",
    "        captions = generator.beam_search(sess, preds)\n",
    "        candidates = ''\n",
    "        output = ''\n",
    "        for i, caption in enumerate(captions):\n",
    "            cap = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n",
    "            cap = ' '.join(cap)\n",
    "            if i == 0:\n",
    "                output = cap\n",
    "            candidates += cap + '\\n'\n",
    "        #print(filename, '\\n', candidates)\n",
    "        dev_text = text_processing(candidates)\n",
    "        perps = 0\n",
    "        for k in k_ls:\n",
    "            tri_addk_prob_dict = add_k_smoothing(3, replaced_tokens_train, unigram_count, k, V)\n",
    "            perps += perplexity(dev_text,3,tri_addk_prob_dict,ADD_K_SMOOTHING)\n",
    "        print(basestring.format(filename, output, perps / len(k_ls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Imagen | Leyenda Modelo A / Perplejidad   | Leyenda Modelo B / Perplejidad |\n",
    "|:------:|:----------------:|:-------------:|\n",
    "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/20.jpg\"> | brownies brownies brownies brownies church shake / 80.88927376112007 | fuck off |\n",
    "| <img width=\"50\" alt=\"50\" src=\"evaldataset/memes/12.png.jpg\"> | lucky rush rush rush rush rush / 80.88927376112007 | fuck off |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Imagen | Leyenda Modelo `A` / Perplejidad  | Leyenda Modelo `B` / Perplejidad |\n",
    "|:------:|:----------------:|:-------------:|\n",
    "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000437409.jpg\"> | ask ask ask burnt seats fora / 1751.52 |  |\n",
    "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000581919.jpg\"> | musica musica starve victoria victoria victoria / 1751.52 |  |\n",
    "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000437984.jpg\"> | facebook facebook 100000 100000 100000 matter / 1751.52 |  |\n",
    "| <img width=\"50\" alt=\"50\" src=\"evaldataset/no_memes/COCO_test2014_000000581911.jpg\"> | kanji kanji matter matter matter matter / 80.89 |  |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpudeepenv",
   "language": "python",
   "name": "cpudeepenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
